# ibetインフラ構成
## 1. 【全体構成】  

- プロダクション、ステージング用２種類のAWSアカウントが存在する。  
- プロダクション用のAWSアカウント上には、プロダクション環境のみ存在する。  
- ステージング用のAWSアカウントには、ステージング環境、開発環境が存在する。  
- 本来は各社ごとにAWSアカウントを分ける方式(現在RelicはNVC用のAWSアカウント配下に存在)  
- セキュリティ確保のため、各社ごとにVPCを分離。  
- 今回は各環境毎に、NVC用VPCと、コミュニティ用VPCの２種類を用意している。
- 開発環境はアプリケーションの開発環境。1EC2上でDocker Composeを使って起動している。  
- ステージング環境はお客様受け入れ＋NVCの営業用の環境。お客様が自由に試用が可能。  
- プロダクション環境はステージングで受け入れが完了したアプリケーションを可動させる環境。

![](./docs/system_overview_v2.png)


### 1.1. node-api クラスタ
![](./docs/apinode_overview_v2.png)


- iOSアプリ(Wallet)から接続を受け付けるためのクラスタ    
- WAF/Shield、外部ALB、Nginx Proxy、内部ALB、APコンテナ、RDS、SQS、SNS、S3、FireBaseを組み合わせて構成される    


#### 1.1.1 WAF/Shield
- 外部からの不正侵入を抑止するために設置    
- 日本国外からのIPアドレスからのアクセス抑止、単位時間あたりの同一IPからの連続アクセス抑止、SQLインジェクション抑止フィルタを実装    
- 外部ALBにアドインしている    


#### 1.1.2 外部ALB
- nginxを冗長構成するため、かつ、HTTPS→HTTPへ復号化を実施するためにPlublicネットワーク上に設置    
- ドメインはRoute53に格納したNVCのドメイン(api.ibet.jp)を利用  
- 証明書はACMにて作成したAmazon作成の証明書を適用    
- Port443でListenしたものを後ろのnginx Proxyの80番ポートにフォワーディング 
- 背後のnginx proxyが全滅して処理を返せない場合、503エラーとステータスコード999を返却(要確認) 
- アクセスログはS3上に格納している  


#### 1.1.3 nginx Proxy
- DMZに配置し、basic認証機能を搭載することでアクセス制御を実装    
- ECSクラスタ上で可動する  
- AWSのALBが定期的にIPアドレスが変わるため、定期的にキャッシュしたDNSを再読込する機能を実装している  
- ログはCloudwatch logsに出力。    


#### 1.1.4 内部ALB
- APコンテナ、Quorumコンテナを冗長化するために、Privateネットワーク上に設置    
- Port80でListenしたものを後ろのAPコンテナの5000番ポートにフォワーディング 
- Port80でListenしたものを後ろのQuorumコンテナの8443番ポートにフォワーディング 
- ログはCloudwatch logsに出力。    


#### 1.1.5 APコンテナ
- iOSアプリから受け付けるWebAPIを提供しているコンテナ    
- Privateネットワーク上に設置している    
- 基本的にサーバチームが実装、テストしたものをECR経由でコンテナごとリリースする 
- コンテナ部分はUbuntuを利用しており、必要最小限度のライブラリのみ搭載されている。 
- ログはCloudwatch logsに出力。    


#### 1.1.6 APコンテナ
- iOSアプリから受け付けるWebAPIと、RDB/Quorumをポーリングして通知を投げるNotificationと、もう一つの３つのコンテナから成り立つ  
- Privateネットワーク上に設置している    
- 基本的にサーバチームが実装、テストしたものをECR経由でコンテナごとリリースする 
- コンテナ部分はUbuntuを利用しており、必要最小限度のライブラリのみ搭載されている。 
- アプリが必要とする定義はタスク定義の環境変数に設定されており、タスク定義を切り替えるだけで各環境で可動する。 
- iOS用のPush通知にApple notification serviceを、Android用のPush通知にFirebaseとSNSを経由して接続をしている。 
- Bankとの連携にSQSを利用している。 
- キャシュ情報やリスティング情報、実行許可コントラクト情報などをRDSに格納。
- アクセス可能な会社のリスト情報などをS3上のWhitelistに格納  
- ログはCloudwatch logsに出力。    


#### 1.1.7 Quorumコンテナ
- 議決権を持たないGeneralノードを配置している  
- 冗長構成をとっており、２つのQuorumコンテナから成り立つ。Act-Act構成だが、切り替えはALBのTargetを明示的に切り替える必要がある。  
- HA構成とせず、手動での切り替えとした理由はQuorumの同期タイミングを考慮したため。１秒以内に切り替えが発生した場合、同期が取られていない情報が見える可能性があるため、自動での切り替えではなく、手動での切り替えとするように設計している。
- Privateネットワーク上に設置している    
- メモリリークが発生していたため、メモリリーク対策を行ったQuorumを格納 
- コンテナ部分はUbuntuを利用しており、必要最小限度のライブラリのみ搭載されている。 
- Quorumが必要とするアドレス情報はタスク定義の環境変数に設定されており、タスク定義を切り替えるだけで各環境で可動する。 
- ログはCloudwatch logsに出力。    


#### 1.1.8 Postgres RDS
- walletからのアクセス要件(24時間365日アクセス)を考慮し、高い可用性を確保するため、RDSを採用。  
- APEC2 上から psqlにてアクセスを行う。  
- ログはCloudwatch logsに出力。    


#### 1.1.9 S3
- アクセス許可を与えられた会社情報及び、エージェントアドレス情報が格納されているリストがある。  


#### 1.1.9 運用
- コンテナ上のCronを使って、定期的にリブートを実施している。  
- バックアップはRDSはマネージドのため不要、アプリケーションはECR上に格納、タスク定義はGithubに格納、Quorumは自動同期のため不要。  
- 監視はディスク、メモリ、CPU等必要最小限の監視のみ実施。  
- リリースはJenkinsにて実装  


### 1.2. satoshi
![](./docs/satoshi_overview_v2.png)


- コミュニティが利用するValicatorを可動させるためのクラスタ    
- ECS上でValidatorとして設定されたQuorumコンテナが4つ稼働している    
  
  
#### 1.2.1 Quorumコンテナ
- Privateネットワーク上に配置    
- ECSクラスタ上で可動する  
- ValidatorとしてBuildされたQuorumコンテナに、Istanbul toolsで発行したキーを付与している  
- ホストEC2上の/home/ubuntu/quorum_data/v[1-4]配下をECSのコンテナからマウントして利用している  
- static-nodes.json,genesis.jsonを配置  
- ログはCloudwatch logsに出力。    



### 1.3. Issuer クラスタ
![](./docs/Issuer_overview_v2.png)


- iOSアプリ(Wallet)から接続を受け付けるためのクラスタ    
- WAF/Shield、外部ALB、Nginx Proxy、内部ALB、APコンテナ、RDS、SQS、SNS、S3、FireBaseを組み合わせて構成される    


#### 1.3.1 WAF/Shield
- 外部からの不正侵入を抑止するために設置    
- 日本国外からのIPアドレスからのアクセス抑止、単位時間あたりの同一IPからの連続アクセス抑止、SQLインジェクション抑止フィルタを実装    
- 外部ALBにアドインしている    


#### 1.3.2 外部ALB
- nginxを冗長構成するため、かつ、HTTPS→HTTPへ復号化を実施するためにPlublicネットワーク上に設置    
- ドメインはRoute53に格納したNVCのドメイン(api.ibet.jp)を利用  
- 証明書はACMにて作成したAmazon作成の証明書を適用    
- Port443でListenしたものを後ろのnginx Proxyの80番ポートにフォワーディング 
- 背後のnginx proxyが全滅して処理を返せない場合、503エラーとステータスコード999を返却(要確認) 
- アクセスログはS3上に格納している  


#### 1.3.3 nginx Proxy
- DMZに配置し、basic認証機能を搭載することでアクセス制御を実装    
- ECSクラスタ上で可動する  
- AWSのALBが定期的にIPアドレスが変わるため、定期的にキャッシュしたDNSを再読込する機能を実装している  
- ログはCloudwatch logsに出力。    


#### 1.3.4 内部ALB
- APコンテナ、Quorumコンテナを冗長化するために、Privateネットワーク上に設置    
- Port80でListenしたものを後ろのAPコンテナの5000番ポートにフォワーディング 
- Port80でListenしたものを後ろのQuorumコンテナの8443番ポートにフォワーディング 
- ログはCloudwatch logsに出力。    


#### 1.3.5 APコンテナ
- iOSアプリから受け付けるWebAPIを提供しているコンテナ    
- Privateネットワーク上に設置している    
- 基本的にサーバチームが実装、テストしたものをECR経由でコンテナごとリリースする 
- コンテナ部分はUbuntuを利用しており、必要最小限度のライブラリのみ搭載されている。 
- ログはCloudwatch logsに出力。    


#### 1.3.6 APコンテナ
- iOSアプリから受け付けるWebAPIと、RDB/Quorumをポーリングして通知を投げるNotificationと、もう一つの３つのコンテナから成り立つ  
- Privateネットワーク上に設置している    
- 基本的にサーバチームが実装、テストしたものをECR経由でコンテナごとリリースする 
- コンテナ部分はUbuntuを利用しており、必要最小限度のライブラリのみ搭載されている。 
- アプリが必要とする定義はタスク定義の環境変数に設定されており、タスク定義を切り替えるだけで各環境で可動する。 
- iOS用のPush通知にApple notification serviceを、Android用のPush通知にFirebaseとSNSを経由して接続をしている。 
- Bankとの連携にSQSを利用している。 
- キャシュ情報やリスティング情報、実行許可コントラクト情報などをRDSに格納。
- アクセス可能な会社のリスト情報などをS3上のWhitelistに格納  
- ログはCloudwatch logsに出力。    


#### 1.3.7 Quorumコンテナ
- 議決権を持たないGeneralノードを配置している  
- 冗長構成をとっており、２つのQuorumコンテナから成り立つ。Act-Act構成だが、切り替えはALBのTargetを明示的に切り替える必要がある。  
- HA構成とせず、手動での切り替えとした理由はQuorumの同期タイミングを考慮したため。１秒以内に切り替えが発生した場合、同期が取られていない情報が見える可能性があるため、自動での切り替えではなく、手動での切り替えとするように設計している。
- Privateネットワーク上に設置している    
- メモリリークが発生していたため、メモリリーク対策を行ったQuorumを格納 
- コンテナ部分はUbuntuを利用しており、必要最小限度のライブラリのみ搭載されている。 
- Quorumが必要とするアドレス情報はタスク定義の環境変数に設定されており、タスク定義を切り替えるだけで各環境で可動する。 
- ログはCloudwatch logsに出力。    


#### 1.3.8 Postgres RDS
- walletからのアクセス要件(24時間365日アクセス)を考慮し、高い可用性を確保するため、RDSを採用。  
- APEC2 上から psqlにてアクセスを行う。  
- ログはCloudwatch logsに出力。    


#### 1.3.9 S3
- アクセス許可を与えられた会社情報及び、エージェントアドレス情報が格納されているリストがある。  


#### 1.3.9 運用
- コンテナ上のCronを使って、定期的にリブートを実施している。  
- バックアップはRDSはマネージドのため不要、アプリケーションはECR上に格納、タスク定義はGithubに格納、Quorumは自動同期のため不要。  
- 監視はディスク、メモリ、CPU等必要最小限の監視のみ実施。  
- リリースはJenkinsにて実装  


### 1.4. bank クラスタ
![](./docs/bank_overview_v2.png)


- iOSアプリ(Wallet)から接続を受け付けるためのクラスタ    
- WAF/Shield、外部ALB、Nginx Proxy、内部ALB、APコンテナ、RDS、SQS、SNS、S3、FireBaseを組み合わせて構成される    


#### 1.4.1 WAF/Shield
- 外部からの不正侵入を抑止するために設置    
- 日本国外からのIPアドレスからのアクセス抑止、単位時間あたりの同一IPからの連続アクセス抑止、SQLインジェクション抑止フィルタを実装    
- 外部ALBにアドインしている    


#### 1.4.2 外部ALB
- nginxを冗長構成するため、かつ、HTTPS→HTTPへ復号化を実施するためにPlublicネットワーク上に設置    
- ドメインはRoute53に格納したNVCのドメイン(api.ibet.jp)を利用  
- 証明書はACMにて作成したAmazon作成の証明書を適用    
- Port443でListenしたものを後ろのnginx Proxyの80番ポートにフォワーディング 
- 背後のnginx proxyが全滅して処理を返せない場合、503エラーとステータスコード999を返却(要確認) 
- アクセスログはS3上に格納している  


#### 1.4.3 nginx Proxy
- DMZに配置し、basic認証機能を搭載することでアクセス制御を実装    
- ECSクラスタ上で可動する  
- AWSのALBが定期的にIPアドレスが変わるため、定期的にキャッシュしたDNSを再読込する機能を実装している  
- ログはCloudwatch logsに出力。    


#### 1.4.4 内部ALB
- APコンテナ、Quorumコンテナを冗長化するために、Privateネットワーク上に設置    
- Port80でListenしたものを後ろのAPコンテナの5000番ポートにフォワーディング 
- Port80でListenしたものを後ろのQuorumコンテナの8443番ポートにフォワーディング 
- ログはCloudwatch logsに出力。    


#### 1.4.5 APコンテナ
- iOSアプリから受け付けるWebAPIを提供しているコンテナ    
- Privateネットワーク上に設置している    
- 基本的にサーバチームが実装、テストしたものをECR経由でコンテナごとリリースする 
- コンテナ部分はUbuntuを利用しており、必要最小限度のライブラリのみ搭載されている。 
- ログはCloudwatch logsに出力。    


#### 1.4.6 APコンテナ
- iOSアプリから受け付けるWebAPIと、RDB/Quorumをポーリングして通知を投げるNotificationと、もう一つの３つのコンテナから成り立つ  
- Privateネットワーク上に設置している    
- 基本的にサーバチームが実装、テストしたものをECR経由でコンテナごとリリースする 
- コンテナ部分はUbuntuを利用しており、必要最小限度のライブラリのみ搭載されている。 
- アプリが必要とする定義はタスク定義の環境変数に設定されており、タスク定義を切り替えるだけで各環境で可動する。 
- iOS用のPush通知にApple notification serviceを、Android用のPush通知にFirebaseとSNSを経由して接続をしている。 
- Bankとの連携にSQSを利用している。 
- キャシュ情報やリスティング情報、実行許可コントラクト情報などをRDSに格納。
- アクセス可能な会社のリスト情報などをS3上のWhitelistに格納  
- ログはCloudwatch logsに出力。    


#### 1.4.7 Quorumコンテナ
- 議決権を持たないGeneralノードを配置している  
- 冗長構成をとっており、２つのQuorumコンテナから成り立つ。Act-Act構成だが、切り替えはALBのTargetを明示的に切り替える必要がある。  
- HA構成とせず、手動での切り替えとした理由はQuorumの同期タイミングを考慮したため。１秒以内に切り替えが発生した場合、同期が取られていない情報が見える可能性があるため、自動での切り替えではなく、手動での切り替えとするように設計している。
- Privateネットワーク上に設置している    
- メモリリークが発生していたため、メモリリーク対策を行ったQuorumを格納 
- コンテナ部分はUbuntuを利用しており、必要最小限度のライブラリのみ搭載されている。 
- Quorumが必要とするアドレス情報はタスク定義の環境変数に設定されており、タスク定義を切り替えるだけで各環境で可動する。 
- ログはCloudwatch logsに出力。    


#### 1.4.8 Postgres RDS
- walletからのアクセス要件(24時間365日アクセス)を考慮し、高い可用性を確保するため、RDSを採用。  
- APEC2 上から psqlにてアクセスを行う。  
- ログはCloudwatch logsに出力。    


#### 1.4.9 S3
- アクセス許可を与えられた会社情報及び、エージェントアドレス情報が格納されているリストがある。  


#### 1.4.9 運用
- コンテナ上のCronを使って、定期的にリブートを実施している。  
- バックアップはRDSはマネージドのため不要、アプリケーションはECR上に格納、タスク定義はGithubに格納、Quorumは自動同期のため不要。  
- 監視はディスク、メモリ、CPU等必要最小限の監視のみ実施。  
- リリースはJenkinsにて実装  



## 2. 【運用】  
運用に必要な情報、手順をここに記載する
- アクセス方法  
- リリース方法  
- 監視方法方法  
- 再起動方法  
- 緊急アクセス方法  
```
手順、コマンドを書く
```

